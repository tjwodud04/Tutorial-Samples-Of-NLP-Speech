{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tacotron2_Gradio_demo",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAJ6x4Zs5zM_"
      },
      "source": [
        "### Gradio Interface\n",
        "\n",
        "![](https://i.ibb.co/982NS6m/header.png)\n",
        "\n",
        "### This notebook requires a GPU runtime to run.\n",
        "### Please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# Tacotron 2 Gradio Demo\n",
        "\n",
        "*Author: NVIDIA and Gradio*\n",
        "\n",
        "**The Tacotron 2 model for generating mel spectrograms from text**\n",
        "\n",
        "\n",
        "### Model Description\n",
        "\n",
        "The Tacotron 2 and WaveGlow model form a text-to-speech system that enables user to synthesise a natural sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow (also available via torch.hub) is a flow-based model that consumes the mel spectrograms to generate speech."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5N544MoM5zNC"
      },
      "source": [
        "%%bash\n",
        "pip install -q numpy scipy librosa unidecode inflect librosa gradio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dinuhyj_5zNC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "outputId": "efb8733b-b70d-4acd-b277-3d43a47a7861"
      },
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "tacotron2 = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_tacotron2')\n",
        "\n",
        "tacotron2 = tacotron2.to('cuda')\n",
        "tacotron2.eval()\n",
        "\n",
        "waveglow = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_waveglow')\n",
        "waveglow = waveglow.remove_weightnorm(waveglow)\n",
        "waveglow = waveglow.to('cuda')\n",
        "waveglow.eval()\n",
        "\n",
        "def inference(text):\n",
        "    # preprocessing\n",
        "    sequence = np.array(tacotron2.text_to_sequence(text, ['english_cleaners']))[None, :]\n",
        "    sequence = torch.from_numpy(sequence).to(device='cuda', dtype=torch.int64)\n",
        "\n",
        "    # run the models\n",
        "    with torch.no_grad():\n",
        "        _, mel, _, _ = tacotron2.infer(sequence)\n",
        "        audio = waveglow.infer(mel)\n",
        "    audio_numpy = audio[0].data.cpu().numpy()\n",
        "    rate = 22050\n",
        "\n",
        "    write(\"audio.wav\", rate, audio_numpy)\n",
        "    return \"./audio.wav\"\n",
        "\n",
        "inputs = gr.inputs.Textbox(label=\"Input Text\")\n",
        "outputs = gr.outputs.Audio(label=\"Output Audio\")\n",
        "\n",
        "\n",
        "title = \"Tacotron 2\"\n",
        "description = \"Gradio demo for The Tacotron 2 model for generating mel spectrograms from text by NVIDIA. To use it, simply add your text or click on one of the examples to load them. Read more at the links below.\"\n",
        "article = \"<p style='text-align: center'><a href='https://arxiv.org/abs/1712.05884'>Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</a> | <a href='https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechSynthesis/Tacotron2'>Github Repo</a></p>\"\n",
        "examples = [\n",
        "            [\"hello world, I missed you\"],\n",
        "            [\"life is like a box of chocolates\"]\n",
        "]\n",
        "\n",
        "gr.Interface(inference, inputs, outputs, title=title, description=description, article=article, examples=examples, analytics_enabled=False).launch();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/nvidia/DeepLearningExamples/archive/torchhub.zip\" to /root/.cache/torch/hub/torchhub.zip\n",
            "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/tacotron2_pyt_ckpt_fp32/versions/19.09.0/files/nvidia_tacotron2pyt_fp32_20190427\n",
            "Using cache found in /root/.cache/torch/hub/nvidia_DeepLearningExamples_torchhub\n",
            "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/waveglow_ckpt_fp32/versions/19.09.0/files/nvidia_waveglowpyt_fp32_20190427\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "This share link will expire in 24 hours. If you need a permanent link, visit: https://gradio.app/introducing-hosted (NEW!)\n",
            "Running on External URL: https://47101.gradio.app\n",
            "Interface loading below...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://47101.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fb4204baf10>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<Flask 'gradio.networking'>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://47101.gradio.app')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpQ4k2_S5zNG"
      },
      "source": [
        "### References\n",
        "\n",
        " - [Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884)\n",
        " - [WaveGlow: A Flow-based Generative Network for Speech Synthesis](https://arxiv.org/abs/1811.00002)\n",
        " - [Tacotron2 and WaveGlow on NGC](https://ngc.nvidia.com/catalog/model-scripts/nvidia:tacotron_2_and_waveglow_for_pytorch)\n",
        " - [Tacotron2 and Waveglow on github](https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/SpeechSynthesis/Tacotron2)"
      ]
    }
  ]
}